{
  "name": "Vr music visualizer",
  "tagline": "A music visualizer based on particle interactions built for Google Cardboard.",
  "body": "# VR_Music_Visualizer :notes:\r\nA music visualizer based on particle interactions built for Google Cardboard.\r\n\r\nThis project was created by Marie Urmano, Jesse Trinity, and Chaz Pearson for Benjamin Lok's Spring 2016 Virtual Reality course as Project 3 Data Visualization.\r\n\r\n## Motivation and Explanation of the Project\r\n\r\nUpon hearing about visualization of a data source, our team immediately thought about modeling sounds in Virtual Reality in a creative way. What originally started out as an idea to change or manipulate the wave with picking, the project evolved as a way to see the wave as part of an environment that can be edited for further understanding by the user. This Google Cardboard application can model speech in sound waves that are modeled by a stream of particle systems that move up and down based on the user's speech. Properties that can be changed by the wave also contribute to the helpful data visualization side of the music visualizer itself. As a result, this project is easily leveraged in virtual reality and is a great example of a creative way to model a data source.\r\n\r\n## Link to a .zip of your code and executable (executable for the mobile device):\r\n\r\n[Project (Including final .apk build)](https://drive.google.com/open?id=0Bzd7Pdy6zQQ-T1U5TmhaeVpxaTA)\r\n\r\n## YouTube Video:\r\nVideo of the 3+ minute experience followed by insight goals, the benefits of experiencing the environment in VR, and a technical description of your system.\r\n\r\n[YouTube Video](https://www.youtube.com/watch?v=4F7HuKbdgv0&feature=youtu.be)\r\n[Link to the video with sound (Copyright issues)](https://drive.google.com/open?id=0Bzd7Pdy6zQQ-dkNERGs0Q3Y4Tnc)\r\n\r\n##Insights Participants Will Gain:\r\nParticipants will (1) identify key components that play into sound systems and (2) learn how bands of sound interact to form sound waves and speech. They will be able to interact with the waves by changing amplitude, wave speed, and wave color to better understand sound wave movement and gain an understanding of the visualization. In addition, the user will also have the opportunity to hear the course of an audio source manipulating the wave, as an addition to recognizing and decoding sound waves that make up speech in the original scene.\r\n\r\n##For each participant, have them write down what they know about the topic contained in the VR experience.\r\n\r\n###Participant 1:\r\n\"I do not know how waves interact together to form sound systems.\"\r\n\r\nInsights Gained:\r\n\"I liked how it looked visually. I understand a little better how waves can work together as a whole to form speech or simulate a song.\"\r\n\r\n###Participant 2:\r\n\"I honestly don't know much about sound and waves.\"\r\n\r\nInsights Gained:\r\n\"It looked really cool to walk inside and look at the simulation from a different perspective. I could see the waves changing in response to the sound intensity.\"\r\n\r\n###Participant 3:\r\n\"I know that different frequencies of sound and amplitudes can effect sound volumes.\"\r\n\r\nInsights Gained:\r\n\"I really liked how the simulation modeled the sound from my voice. It showed how my voice can be separated into different components.\"\r\n\r\n## In your report, discuss whether your predictions were accurate. Why or why not.\r\n\r\nOur predictions, though a little too positive on the outlook, did model the participant's responses to their insights gained. It was often seen as a very pretty tool that was addicting to watch, but the interactions and changing of components on the experience were what really contributed to it being a learning tool as well. As a result, this visualizer did provide significant insights and also an aesthetic that is supported through virtual reality and a first person perspective.\r\n\r\n## Have three people rate simulator sickness after the experience. Report averages and discuss what factors resulted in the simulator sickness values reported.\r\n\r\nOur three people gained the following scores:\r\n6, 12, 11.\r\nAverage: 9.66\r\n\r\n###How different components of the experience impacted the reported simulator sickness:\r\n\r\nThis virtual reality simulation, in its nature, shows many moving particles and ways for the user to get dizzy or eye strains. However, in order to visualize sound waves, the particles did a great job in showing a scene that was very accurate and real to show true data visualization. The depth into how close the user was to the waves definitely impacted the simulation, as well as the fast motion of the music or speech that was picked up. As a result, though these components definitely contributed to a higher simulation sickness score, they still provided a learning objective and an awesome way for the user to experience modeled data.\r\n\r\n## Identify how the experience leveraged concepts found in the VR Book sections Chapter 19.\r\n\r\nUsing 19.1, we utilized a wireless system besides that of the keyboard hand controller in order for the user to feel less trapped in the simulation and free to move about exploring the sound wave. Also utilizing 19.2, we do have a way for users to alter the environment to their liking if a color makes them feel sick or the wave speed is too much to look at. Additionally, seen in 19.4, our scene remains dark in order for the user to feel less of a perception of flicker.\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}